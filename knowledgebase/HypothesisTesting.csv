Test Name,Type (Parametric/Non-parametric),Background,When to Use,Assumptions,Data Types Required,Recommend Sample Size,Test Statistic,How to interpret results,Skill Level,Counterpart
One-Sample t-Test,Parametric,Developed by William S. Gosset ('Student') in 1908 as a test for a population mean:contentReference[oaicite:0]{index=0}.,To determine if the mean of a single sample differs from a known or target value:contentReference[oaicite:1]{index=1}.,"Requires approximately normally distributed data (or n large by CLT), independent observations, and uses sample standard deviation as an estimate:contentReference[oaicite:2]{index=2}:contentReference[oaicite:3]{index=3}.",Numeric continuous outcome (one sample).,n ≥ 30 recommended if normality is not assured (allows use of t-approximation via CLT):contentReference[oaicite:4]{index=4}.,"t statistic = (\\bar{x} - μ₀) / (s/√n), compared against t-distribution (df = n-1).","If p-value < α, reject H₀ (conclude the population mean differs from the target); if p ≥ α, fail to reject H₀ (no significant difference).",Green Belt (fundamental statistical test).,One-Sample Sign Test or 1-Sample Wilcoxon Signed-Rank Test (non-parametric median test):contentReference[oaicite:5]{index=5}.
Two-Sample t-Test (Independent),Parametric,"Originating from Student's t-test (Gosset), extended to compare means of two independent groups; uses pooled variance under equal variance assumption:contentReference[oaicite:6]{index=6}.",To test if the means of two independent populations are significantly different (e.g. control vs treatment group means).,"Assumes each sample is from a normal distribution, samples are independent, and variances are equal (for pooled version; Welch’s variant relaxes equal variance):contentReference[oaicite:7]{index=7}:contentReference[oaicite:8]{index=8}.",Numeric continuous outcome; one categorical independent variable with two levels (groups).,Preferably n ≥ 30 in each group if normality is uncertain (CLT improves robustness); smaller samples acceptable if data are approximately normal.,"t statistic = (\\bar{x}_1 - \\bar{x}_2) / (s_p * √(1/n₁ + 1/n₂)), tested with df ≈ n₁+n₂-2 (or adjusted for Welch).","If p < α, conclude the two group means differ significantly; if p ≥ α, cannot detect a significant mean difference.",Green Belt (common test for comparing two processes).,Mann-Whitney U Test (non-parametric two-sample comparison):contentReference[oaicite:9]{index=9}.
Paired t-Test,Parametric,A specialized t-test (also introduced by Gosset) for matched pairs: effectively a one-sample t-test on the differences between paired observations:contentReference[oaicite:10]{index=10}.,To determine if the mean difference between two related measurements (e.g. before vs after on same subjects) is zero or not.,"Assumes differences are approximately normally distributed, pairs are matched/dependent but different pairs are independent of each other.",Numeric continuous outcome measured in pairs (e.g. repeated measures on same unit).,"If normality of differences is uncertain, aim for ~30 paired samples; smaller paired samples are acceptable if differences appear symmetric/normal.","t statistic = (\\bar{d}) / (s_d/√n), where \\bar{d} is mean of differences, s_d is std dev of differences; uses t-distribution (df = n-1).","If p < α, reject H₀ (significant difference between paired measurements); if p ≥ α, not enough evidence of a difference.",Green Belt (used for before-and-after comparisons).,Wilcoxon Signed-Rank Test (non-parametric paired test):contentReference[oaicite:11]{index=11}.
One-Way ANOVA,Parametric,"Developed by Ronald Fisher in the 1920s as Analysis of Variance, to generalize t-tests to multiple groups:contentReference[oaicite:12]{index=12}.",To test if three or more group means are all equal or if at least one differs (compares variability between vs within groups).,"Assumes each sample is from a normal distribution, observations independent, and approximately equal variances across groups (homoscedasticity):contentReference[oaicite:13]{index=13}:contentReference[oaicite:14]{index=14}.",Numeric continuous outcome; one categorical factor with 3+ levels (independent groups).,Recommended ≥ 10-20 observations per group (≥ 30 if normality is questionable) to ensure robustness of F-test assumptions:contentReference[oaicite:15]{index=15}:contentReference[oaicite:16]{index=16}.,"F statistic = MS_between / MS_within, follows F-distribution (df1 = k-1, df2 = N-k).","If p < α, reject H₀ (conclude not all means are equal; at least one group mean differs). Further pairwise comparisons (post-hoc tests) identify which means differ.",Green / Black Belt (Green Belt covers basics; Black Belt uses extensively in DOE and complex analyses).,Kruskal-Wallis H Test (non-parametric ANOVA alternative):contentReference[oaicite:17]{index=17}.
Repeated Measures ANOVA,Parametric,"Extends ANOVA for within-subject designs; developed to analyze multiple related measurements (e.g. time series on same subjects), requiring sphericity assumption (Mauchly’s test often used):contentReference[oaicite:18]{index=18}.",To test if the means of three or more related conditions (or time points) are equal (controls for subject-to-subject variability).,"Assumes normal distribution of differences, sphericity (equal variances of differences between all pairs of conditions), and independent subjects (no between-subject effects).",Numeric continuous outcome measured on the same experimental units across conditions.,"Typically need ≥ 10 subjects (blocks); more increases power. If sphericity is violated, use corrections (Greenhouse-Geisser) or a non-parametric alternative. Ensure enough subjects to estimate variability reliably.",F statistic with repeated measures design (with appropriate df adjustments if sphericity violated) comparing between-condition variance to residual variance.,"If p < α, reject H₀ (at least one time/treatment mean differs). A significant result indicates a time/treatment effect; follow-up with post-hoc or trend analysis to locate differences.",Black Belt (advanced analysis of longitudinal or blocked data).,Friedman Test (non-parametric repeated-measures analog):contentReference[oaicite:19]{index=19}.
Chi-Square Goodness-of-Fit Test,Non-parametric,"Introduced by Karl Pearson in 1900 as one of the first modern statistical tests:contentReference[oaicite:20]{index=20}, it checks how observed categorical frequencies compare to expected frequencies under a hypothesized distribution.",To determine if an observed frequency distribution for a single categorical variable differs from an expected distribution (e.g. to test if data follow a claimed proportion across categories).,Assumes independent observations and sufficiently large sample such that expected counts in each category are ≥ 5 (for validity of chi-square approximation).,"Categorical outcome (one categorical variable with two or more possible categories), compared against expected proportions.","Generally requires a total sample large enough to give each category an expected count of at least 5. If sample is small, exact tests should be used instead of chi-square approximation.","Test statistic χ² = Σ ((Observed - Expected)² / Expected), which follows a χ² distribution (df = number of categories - 1) under H₀.","If p < α, reject H₀ (the observed distribution differs significantly from the expected pattern); if p ≥ α, no significant deviation from expected distribution is detected.",Green Belt (basic analysis of categorical data).,"Exact multinomial test (for small samples, uses exact probabilities) – otherwise no direct parametric counterpart since χ² is itself the standard method."
Chi-Square Test of Independence,Non-parametric,"A generalization of Pearson’s chi-square (Karl Pearson, 1900) to contingency tables, used to assess if two categorical variables are associated:contentReference[oaicite:21]{index=21}.","To test whether two categorical variables are independent (e.g. whether proportions differ across groups, such as defect rate by machine or preference by region).","Assumes a random sample, independent observations, and expected frequency ≥ 5 in each cell (or at most <20% of cells with expected <5) for the χ² approximation to be valid.",Two categorical variables (forming an R×C contingency table) with frequency counts in each combination of categories.,"Total sample size should be large enough that expected counts ≥ 5 per cell. If this assumption fails (small sample or sparse table), use Fisher’s Exact Test for 2×2 tables or other exact methods for larger tables.","Test statistic χ² = Σ ((O_{ij}-E_{ij})²/E_{ij}) summed over all cells, approximately χ² distributed (df = (R-1)(C-1)) under H₀ of independence.","If p < α, reject H₀ (conclude the variables are not independent, i.e. there is a significant association between them). If p ≥ α, no significant association is detected.",Green Belt (commonly applied to analyze categorical factors in projects).,"Fisher’s Exact Test (for 2×2 cases with small sample sizes, an exact alternative to χ²)."
One-Sample Proportion Test,Parametric,"Based on normal approximation to binomial (using a z-test), widely used in quality control to test if a proportion meets a target; the approximation becomes accurate for large samples (historically developed alongside early 20th century sampling theory).","To check if a population proportion (e.g. defect rate, yes/no probability) equals a specified value (H₀: p = p₀).",Assumes a binomially distributed outcome with a sufficiently large sample so that np₀ and n(1-p₀) ≥ 5 (so the sampling distribution of the proportion can be approximated by normal).,Binary (dichotomous) outcome in one sample (success/failure data).,"n large enough to have ≥ 5 expected successes and failures (rule of thumb; for better accuracy ≥ 10 of each). If sample sizes are small, a Binomial exact test is recommended.","Test statistic z = (\\hat{p} - p₀) / sqrt(p₀(1-p₀)/n), which is approximately standard normal under H₀.","If p-value < α, reject H₀ (the observed proportion differs significantly from p₀); if p ≥ α, no significant difference from the target proportion is found.",Green Belt (common in defect rate or compliance testing).,Exact Binomial Test (non-parametric exact counterpart for proportion when n is small).
Two-Sample Proportion Test,Parametric,Uses a normal (z) approximation or chi-square for 2×2 contingency tables; historically related to Pearson’s chi-square. Compares two group proportions (e.g. success rates) under large-sample conditions.,"To test if two independent proportions are equal (H₀: p₁ = p₂), for example comparing defect rates between two processes or response rates between two groups.",Assumes each sample is binomial with enough sample size that the expected counts of successes and failures in both groups ≥ 5 (ensuring normal approximation validity). Observations between and within samples are independent.,Binary outcome for two independent groups (2×2 contingency data).,"Each group should have at least ~30 observations or at minimum ≥5 expected successes and failures per group. If sample sizes are small or counts are low, use Fisher’s exact test instead of the z-approach.","Test statistic z = (\\hat{p}_1 - \\hat{p}_2) / sqrt(\\hat{p}(1-\\hat{p})(1/n₁+1/n₂)), where \\hat{p} is pooled proportion under H₀; approximate normal distribution used (or equivalently χ² with 1 df for the squared version).","If p < α, reject H₀ (significant difference between the two proportions); if p ≥ α, fail to reject H₀ (no significant difference in proportions).","Green Belt (useful for comparing defect percentages, survey yes-rates, etc.).","Fisher’s Exact Test (non-parametric exact alternative for two proportions, especially when sample size is small or assumptions for z-test fail)."
Shapiro-Wilk Test (Normality),Non-parametric,"Published in 1965 by Samuel Shapiro and Martin Wilk:contentReference[oaicite:22]{index=22}, it provides a test statistic W to assess whether data come from a normal distribution (powerful for detecting non-normality).",To test if a dataset is approximately normally distributed (used as a prerequisite check before applying parametric tests).,"Assumes independent observations. It specifically tests normality; no assumption of normality is required (that is what is being tested). However, the test may be too sensitive for large n (detects minor departures):contentReference[oaicite:23]{index=23}.",Continuous numeric data (one variable) – requires an adequate sample (typically 3 ≤ n ≤ 5000 for valid use).,"Works for small to moderate sample sizes. For n > ~50, even small deviations can yield significant p-values:contentReference[oaicite:24]{index=24}, so normality tests are most informative for n roughly 20–300. Very large samples may always appear non-normal.",Test statistic W is computed from a weighted sum of ordered sample values; W ranges from 0 to 1. Critical values come from simulations.,"If p < α, reject H₀ (data deviate significantly from normal distribution); if p ≥ α, do not reject H₀ (no evidence against normality).",Green / Black Belt (all practitioners check assumptions; Green Belts use normality tests in Analyze phase; Black Belts for more rigorous validation).,Anderson-Darling Test (another normality/goodness-of-fit test that gives more weight to tail behavior):contentReference[oaicite:25]{index=25}.
Anderson-Darling Test (Normality),Non-parametric,"Introduced by T.W. Anderson and D.A. Darling in the 1950s, it's an EDF (empirical distribution function) test that refines the Kolmogorov-Smirnov approach by emphasizing tail differences:contentReference[oaicite:26]{index=26}.",To test if data come from a specified distribution (commonly used for normality testing in Six Sigma tools like Minitab).,Assumes a continuous distribution for the test’s null hypothesis; requires independent samples. It uses the known form of the target distribution in calculating a more sensitive test statistic (so critical values are specific to that distribution):contentReference[oaicite:27]{index=27}.,"Continuous data for a single variable, often used to test normality or other distributions (Weibull, exponential, etc.).","A moderate sample is needed for stable results (say 8 < n < 5000). Very small samples have little power; very large samples will flag even minor deviations as significant, so context is needed in interpretation:contentReference[oaicite:28]{index=28}.",Test statistic A² is computed from the cumulative differences between empirical and theoretical distribution; larger A² indicates more deviation. Critical values depend on the distribution tested and sample size.,"If p < α, reject H₀ (sample is unlikely from the specified distribution); if p ≥ α, no significant evidence against the distribution fit.","Green / Black Belt (commonly part of normality checks in software output; Green Belts encounter it via tools, Black Belts understand its nuances).","Shapiro-Wilk Test (alternative normality test, especially for smaller samples):contentReference[oaicite:29]{index=29}."
F-Test (Two-Sample Variance),Parametric,"A classical test for homogeneity of two variances, dating back to early analysis of variance development (F-distribution named after Fisher). Sensitive to normality assumption, it has largely been supplanted by more robust tests for general use.","To determine if two independent samples have equal variances (H₀: σ₁² = σ₂²), often as a preliminary check before a two-sample t-test or as a standalone test of variability.","Assumes both samples are drawn from normal populations and that samples are independent. Even mild departures from normality can affect its validity, making it less robust.",Numeric continuous measurements from two independent groups.,"Each sample ideally n ≥ 20 (to better approximate normal and to have reasonable power). Very small samples make the test unreliable, and non-normal data can invalidate results; if normality is suspect, use Levene’s test instead.","Test statistic F = s₁²/s₂² (ratio of sample variances). Under H₀ and normality, F follows an F-distribution (df1=n₁-1, df2=n₂-1).","If p < α, reject H₀ (conclude variances differ significantly); if p ≥ α, no evidence that variances differ (assume equal variability).","Black Belt (aware of it, though in practice Levene’s test is usually preferred for variance comparison).",Levene’s Test (non-parametric robust test for equality of variances).
Bartlett’s Test (Equal Variances),Parametric,"Proposed by M.S. Bartlett in 1937:contentReference[oaicite:30]{index=30}, it generalizes the two-sample variance F-test to k samples. It evaluates if multiple group variances are equal, but is highly sensitive to deviations from normality.",To test the hypothesis that the variances of several independent groups are equal (homogeneity of variance) – commonly used in conjunction with ANOVA assumptions.,Assumes each group is normally distributed and samples are independent. Non-normal data can cause Bartlett’s test to falsely indicate variance differences (hence alternatives are used if normality is doubtful).,Numeric continuous outcome in k independent groups.,Needs sufficient sample in each group (≥ 15-20 per group is helpful) because small samples might not detect variance differences and non-normality can distort results. Use only if normality roughly holds; otherwise prefer Levene/Brown-Forsythe tests.,Test statistic approximates χ² = (N-k)*ln(pooled variance) - Σ((n_i-1)*ln(s_i²)) (Bartlett’s M); under H₀ it follows a χ² distribution with df = k-1 (with a correction factor).,"If p < α, reject H₀ (at least one group’s variance differs significantly); if p ≥ α, no evidence against equal variances assumption.",Black Belt (understands it for theoretical completeness; in practice may opt for robust methods).,Levene’s Test (non-parametric alternative less sensitive to non-normality).
Levene’s Test (Equal Variances),Non-parametric,"Introduced by Howard Levene in 1960:contentReference[oaicite:31]{index=31}, it provides a robust test for equal variances across groups by analyzing absolute deviations. Less sensitive to non-normality than Bartlett’s, it became a standard variance homogeneity test (later refined by Brown & Forsythe in 1974).",To assess whether the variances of two or more groups are equal without assuming normal distributions (supports ANOVA assumption checking or general variability comparisons).,"Assumes samples are independent and roughly that groups have a similar shape distribution (Levene’s test using medians is especially robust to non-normal outliers). Does not require normality, making it applicable to a broad range of data distributions:contentReference[oaicite:32]{index=32}.",Numeric continuous data in two or more independent groups.,Works for moderate sample sizes (each group ideally n ≥ 5). More data improves power to detect variance differences. Very small group sizes may not detect differences; very large N can find trivial differences significant.,"Test statistic is essentially an ANOVA on transformed data: compute |X_{ij} - \\tilde{X}_j| (deviation from group median or mean), then an F statistic on these absolute deviations:contentReference[oaicite:33]{index=33}. Under H₀, F is not significant; if significant, variances differ.","If p < α, reject H₀ (at least one group variance is significantly different); if p ≥ α, variances can be treated as homogeneous.",Black Belt (commonly used in practice for checking equal variances assumption in ANOVA or comparing process variability).,Bartlett’s Test (parametric counterpart when normality holds):contentReference[oaicite:34]{index=34}.
Mann-Whitney U Test,Non-parametric,"Based on work by Frank Wilcoxon (1945) and extended by Henry Mann & Donald Whitney (1947):contentReference[oaicite:35]{index=35}:contentReference[oaicite:36]{index=36}, it is also known as the Wilcoxon rank-sum test. It compares the distributions of two independent groups using ranks.",To test if two independent samples come from populations with the same distribution/median. Often used as a substitute for the two-sample t-test when normality is not met or with ordinal data.,"Assumes samples are independent, data are at least ordinal. It specifically assumes the two distributions are similarly shaped under H₀ (tests for a shift in location). No assumption of normality; tolerant of outliers and skewed data.",Ordinal or continuous outcome in two independent groups.,"Can be used with small sample sizes (even n < 10 per group), though its p-value is discrete; for n > ~20 per group, the normal approximation is accurate:contentReference[oaicite:37]{index=37}:contentReference[oaicite:38]{index=38}. Generally, at least 5 observations per group are recommended for minimum reliability.",Test statistic U is the count of “wins” out of all pairwise comparisons between groups (or equivalently based on rank sums); for larger samples U is converted to a z-score using mean and variance of U:contentReference[oaicite:39]{index=39}:contentReference[oaicite:40]{index=40}.,"If p < α, reject H₀ (the two samples differ in central tendency; medians likely not equal); if p ≥ α, insufficient evidence of a difference between groups.",Black Belt (understands and applies non-parametric tests for two-group comparisons).,Two-Sample t-Test (parametric counterpart for means when assumptions are met):contentReference[oaicite:41]{index=41}.
Wilcoxon Signed-Rank Test,Non-parametric,"Introduced by Frank Wilcoxon in 1945:contentReference[oaicite:42]{index=42}, it is a non-parametric alternative to the paired t-test (or one-sample t-test) that uses rank sums of positive and negative differences. It extends the simpler sign test by accounting for magnitude of differences.","To test if the median of a symmetric distribution differs from a target value, or if the median difference in paired observations is zero (e.g. before vs after). Commonly used when the paired differences are not normally distributed.","Assumes differences come from a symmetric continuous distribution (for validity of using ranks around zero). Pairs (or one-sample data) are independent. It does not require normality, only that data can be ranked and differences roughly symmetric around the median.",Ordinal or continuous outcome in paired data (or a single sample versus a hypothesized median).,"Can handle small samples (n as low as 5 pairs), with exact p-values available. For n ≥ 10, approximate methods (normal approximation with continuity correction) can be used. As n grows large (>25), the test statistic’s distribution approaches normal by CLT on ranks.","Test statistic W is typically the sum of ranks of positive differences (or the smaller of positive vs negative rank sums). Under H₀ of zero median difference, W’s distribution is obtained from tables or approximated by a z-score.","If p < α, reject H₀ (significant evidence of a non-zero median or median difference); if p ≥ α, differences are not statistically significant.",Black Belt (often needed for non-parametric paired comparisons in non-normal scenarios).,Paired t-Test (parametric counterpart when differences are normally distributed):contentReference[oaicite:43]{index=43}.
Sign Test,Non-parametric,"One of the oldest non-parametric tests, used by John Arbuthnot as early as 1710:contentReference[oaicite:44]{index=44}, it uses the signs of differences to test medians without considering magnitudes. It's essentially a simple binomial test on the direction of change or position relative to a median.","To test if a population median equals a specified value or if one member of a pair tends to be greater than the other (in paired scenarios). For example, to see if median improvement is nonzero or if median of a sample differs from a target.","Assumes observations/pairs are independent. It does not assume any specific distribution for the data (only that the probability of an observation being above or below the hypothesized median is 50% under H₀). It ignores magnitude of differences, making it robust but less powerful than rank tests.",Ordinal or continuous data (for one-sample median test or paired comparisons expressed as plus/minus signs).,"Can be used with very small samples (even n < 10). The test is based on a binomial distribution with p=0.5; as n increases, normal approximation to binomial can be applied. With extremely small n, power is low but the test is still valid.","Test statistic is the count of positive differences (or “successes”) out of n (ignoring any ties). Under H₀, this count ~ Binomial(n, 0.5).","If p < α (e.g., two-tailed binomial probability of that extreme an imbalance), reject H₀ (median is significantly different from the hypothesized value or there is a consistent pairwise difference); if p ≥ α, no significant median difference found.","Black Belt (conceptually simple, but used as a fallback for very non-normal or ordinal data; seldom needed if Wilcoxon is applicable).","One-Sample t-Test (parametric test for mean, analogous when distribution assumptions hold):contentReference[oaicite:45]{index=45}."
Mood’s Median Test,Non-parametric,"Developed by Brown and Mood in 1948:contentReference[oaicite:46]{index=46} as a chi-square based test for medians, it determines if multiple samples have the same median by categorizing data relative to the overall median. It's less powerful than rank-based tests but very assumption-light.",To test whether the medians of two or more independent groups are identical. Useful as a simple alternative to one-way ANOVA when the normality assumption fails and one is interested specifically in medians.,"Assumes independent samples. Does not assume normality or even identical shapes of distributions – it only focuses on median differences. However, it requires that the data can be meaningfully ordered. It is insensitive to differences in distribution shape other than median shifts:contentReference[oaicite:47]{index=47}.",Ordinal or continuous data in two or more independent groups.,"Works for small or large sample sizes. Each group should ideally contribute several observations above and below the overall median for the chi-square approximation to hold (expected counts ≥ 5). For very small samples, exact calculations or other tests may be preferable.","Test statistic is based on a contingency table of counts: each observation is classified as above or below the grand median, and a Pearson χ² is computed (df = number of groups - 1):contentReference[oaicite:48]{index=48}.","If p < α, reject H₀ (at least one group median differs); if p ≥ α, cannot detect a difference in medians between groups.","Black Belt (for completeness; other tests like Kruskal-Wallis are usually preferred due to higher power, but Mood’s test is useful with severe outliers or non-identical variances).","One-Way ANOVA (parametric test on means; Kruskal-Wallis is another non-parametric counterpart that tests distribution location differences, not just medians):contentReference[oaicite:49]{index=49}."
Kruskal-Wallis H Test,Non-parametric,"Developed by William Kruskal and W. Allen Wallis in 1952:contentReference[oaicite:50]{index=50}, it extends the Mann-Whitney idea to k groups. It's effectively a one-way ANOVA on ranks, providing a distribution-free test for comparing multiple independent samples.",To determine if three or more independent samples come from the same distribution (specifically if their median or overall rank distributions are equal). Used in place of one-way ANOVA when normality or equal variance assumptions are violated.,"Assumes samples are independent and that the response is at least ordinal. It assumes the distributions have a similar shape under H₀ (so that differences are mainly in location). Does not require normality; moderately robust to outliers, but extremely differing distribution shapes can affect interpretation:contentReference[oaicite:51]{index=51}.","Ordinal or continuous data in k independent groups (k ≥ 3, though it can be used for k=2 as well, equivalent to Mann-Whitney).","Can handle small sample sizes in each group (e.g. n as low as 5 per group), but the chi-square approximation is best when total N is larger (say N ≥ 15). For very small samples, exact critical values can be used. Groups need not have equal size, though many ties across groups can reduce accuracy (a tie correction exists).","Test statistic H = (12/(N(N+1))) * Σ_{groups} [n_i*(\\bar{R}_i)^2] - 3(N+1), which follows approximately a χ² distribution with df = k-1 under H₀:contentReference[oaicite:52]{index=52}. (\\bar{R}_i is the average rank in group i.)","If p < α, reject H₀ (at least one group’s distribution differs – likely a median difference among groups). It doesn’t pinpoint which groups differ; post-hoc multiple comparison tests (e.g. Dunn’s test) are needed to identify pairwise differences.",Black Belt (commonly applied for non-parametric analysis of variance in analyze phase or non-normal DOE results).,One-Way ANOVA (parametric counterpart for comparing multiple means):contentReference[oaicite:53]{index=53}.
Friedman Test,Non-parametric,"Developed by Milton Friedman in the 1930s:contentReference[oaicite:54]{index=54} as a non-parametric alternative to repeated measures ANOVA, it analyzes block designs by ranking each block’s results. It’s essentially a two-way ANOVA on ranks (one factor being subjects/blocks, the other treatments).",To test if there are differences in treatments across multiple attempts/trials in a blocked or repeated measures scenario (e.g. comparing three or more treatments on the same subjects). It indicates if at least one treatment median is different.,"Assumes data consist of blocks (e.g. subjects) each measured under all k conditions. Only requirement is that within each block, the measurements can be ranked (ordinal or continuous). No normality needed. It assumes no interaction between blocks and treatments (i.e., treatment effects are consistent across blocks):contentReference[oaicite:55]{index=55}.",Ordinal or continuous outcome measured in a blocked manner (each of N blocks yields one observation for each of k treatments/conditions).,"Each block should have all treatments observed. Works with small sample sizes (even as few as 4 or 5 blocks), but if blocks are very few the test has low power. For larger block counts (n > 15 or so), the χ² approximation for the test statistic is reliable:contentReference[oaicite:56]{index=56}.","Test statistic Q = (12/(n*k*(k+1))) * Σ_{j}(R_j^2) - 3n(k+1), where R_j is the sum of ranks for treatment j within each block. Under H₀ of no treatment differences, Q ~ χ² with df = k-1 (for sufficiently large n). For small n, exact critical values should be used.","If p < α, reject H₀ (at least one treatment median is significantly different). A significant result indicates a treatment effect; follow-up with post-hoc pairwise comparisons (e.g. Nemenyi test) to determine which treatments differ:contentReference[oaicite:57]{index=57}:contentReference[oaicite:58]{index=58}.",Black Belt (especially relevant for non-parametric DOE or repeated measures in analyses).,Repeated Measures ANOVA (parametric counterpart when normality and sphericity hold):contentReference[oaicite:59]{index=59}.
McNemar’s Test,Non-parametric,"Introduced by Quinn McNemar in 1947 as a test for paired categorical data (2×2 table) changes. It examines the discordant pairs in before-after or matched case-control studies, using a simple chi-square statistic on the off-diagonal counts.:contentReference[oaicite:60]{index=60}","To test if there is a significant change in proportions for paired binary observations (e.g., success/failure before vs after for the same subjects, or yes/no responses from matched pairs). Specifically, H₀: the probability of success in state1 equals that in state2 for the population.","Assumes pairs are independent of each other. The data are arranged in a 2×2 contingency table of paired outcomes. It requires a reasonable number of discordant pairs; if very few discordant pairs, power is low (and an exact binomial test should be considered). No assumption of normality or large sample beyond needing some discordant counts.",Dichotomous (binary) outcome measured twice on the same subject or matched pair.,"Works even with moderate sample sizes. Ideally, expect at least ~10 discordant pairs for the chi-square approximation; if total pairs are small (say < 20), an exact McNemar’s (binomial) test can be used. For larger pair counts, the chi-square with continuity correction is often applied.","Test statistic χ² = (|b - c| - 1)² / (b + c), where b and c are the counts of discordant pairs (one type of outcome changed vs the other). Under H₀ (no difference in proportions), this approximately follows χ² with 1 df.","If p < α, reject H₀ (there is a significant change in proportions between the two paired measurements); if p ≥ α, no significant change is detected.",Black Belt (especially in improvement projects analyzing before/after binary metrics or paired categorical data).,N/A – there is no exact parametric counterpart (McNemar’s is the standard approach for paired categorical data; analogous in spirit to a paired t-test but for binary outcomes).
Tukey’s HSD Test,Parametric,"Proposed by John Tukey in 1949:contentReference[oaicite:61]{index=61}, it’s a post-hoc multiple comparison procedure following ANOVA. It uses the Studentized range (Q) distribution to maintain family-wise error rate when identifying which means differ. Often referred to as “Tukey’s Honestly Significant Difference.”",To pinpoint which specific group means differ after finding a significant one-way ANOVA result. It compares all possible pairs of group means to determine which differences are statistically significant.,"Assumes the ANOVA model assumptions: normality within groups, equal variances, independent observations. Also assumes a balanced or nearly balanced design for exact significance levels (though it can be used with unequal n with adjustments). Valid only after an overall ANOVA finds significance (controls Type I error across multiple comparisons).","Numeric continuous outcome, categorical factor with multiple levels (same data structure as ANOVA). Conducted only if ANOVA indicates at least one mean difference.","Each group ideally should have a reasonable sample size (e.g. ≥ 10). The test’s accuracy improves with equal or similar sample sizes. For very small groups, Tukey’s test may be conservative; large group sizes make detection easier. Typically applied after ANOVA with sufficient power (say total N > 20).",Test statistic for comparing group i and j: Q = (\\bar{x}_i - \\bar{x}_j)/√(MS_within/2 * (1/n_i + 1/n_j)). Q is evaluated against the Studentized range distribution for k means and error df. It yields a simultaneous confidence interval for each pair difference and a p-value for each comparison.,"Any pair with p < α (or whose confidence interval for mean difference excludes 0) is declared significantly different. Results are interpreted as which specific groups have significantly different means, while controlling the overall α for all pairs.","Black Belt (knowledge of DOE/ANOVA includes post-hoc analysis; software does computations, but Black Belts understand how to interpret Tukey’s results).","Dunn’s Test (non-parametric post-hoc for Kruskal-Wallis, comparing rank sums pairwise with adjusted p-values):contentReference[oaicite:62]{index=62}."
Dunn’s Multiple Comparison Test,Non-parametric,"Introduced by Olive Dunn in 1964, it is a post-hoc procedure for non-parametric analyses (like after a Kruskal-Wallis test). It performs pairwise rank comparisons between groups using a Bonferroni or similar correction to control family-wise error. Essentially a Tukey-type method for ranked data.",To identify which specific pairs of groups differ in a non-parametric setting (typically following a significant Kruskal-Wallis test). It tests all pairwise group differences in median/rank with adjusted significance to avoid inflating Type I error.,"Assumes an overall significant Kruskal-Wallis result (so at least one group differs). Uses the same assumptions as Kruskal-Wallis: independent samples, ordinal or continuous data. Requires that data in each pairwise comparison can be ranked combined. Dunn’s test handles unequal group sizes and adjusts p-values for multiple comparisons.",Ordinal or continuous outcome in multiple independent groups (post-hoc analysis after a global non-parametric test).,"Generally effective with moderate to large samples. For each pairwise comparison, the sample sizes of the two groups inform the variance of rank sum difference. Sufficient total N is needed since multiple comparisons reduce power; if groups are very small, results may be inconclusive. P-value adjustments (Bonferroni/Holm) demand a larger effect to reach significance.","Test statistic for comparing group i vs j: based on difference in average ranks between the two groups, normalized by the standard error of rank differences. Often reported as Z or adjusted p-values. P-values are corrected for the number of comparisons (e.g., Bonferroni divides α by number of pairs).","If an adjusted p < α for a specific pair, that pair’s medians differ significantly. Dunn’s test output typically lists which group pairs have significant differences after correction, while maintaining the overall error rate.",Black Belt (advanced analysis for non-parametric post-hoc comparisons when using rank-based tests).,Tukey’s HSD Test (parametric equivalent for pairwise comparisons after ANOVA):contentReference[oaicite:63]{index=63}.
